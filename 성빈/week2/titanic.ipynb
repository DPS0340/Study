{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d187e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd7348d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0           0    male  22.0                   1      0   7.2500   Third   \n",
      "1           1  female  38.0                   1      0  71.2833   First   \n",
      "2           1  female  26.0                   0      0   7.9250   Third   \n",
      "3           1  female  35.0                   1      0  53.1000   First   \n",
      "4           0    male  28.0                   0      0   8.4583   Third   \n",
      "..        ...     ...   ...                 ...    ...      ...     ...   \n",
      "622         0    male  28.0                   0      0  10.5000  Second   \n",
      "623         0    male  25.0                   0      0   7.0500   Third   \n",
      "624         1  female  19.0                   0      0  30.0000   First   \n",
      "625         0  female  28.0                   1      2  23.4500   Third   \n",
      "626         0    male  32.0                   0      0   7.7500   Third   \n",
      "\n",
      "        deck  embark_town alone  \n",
      "0    unknown  Southampton     n  \n",
      "1          C    Cherbourg     n  \n",
      "2    unknown  Southampton     y  \n",
      "3          C  Southampton     n  \n",
      "4    unknown   Queenstown     y  \n",
      "..       ...          ...   ...  \n",
      "622  unknown  Southampton     y  \n",
      "623  unknown  Southampton     y  \n",
      "624        B  Southampton     y  \n",
      "625  unknown  Southampton     n  \n",
      "626  unknown   Queenstown     y  \n",
      "\n",
      "[627 rows x 10 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 627 entries, 0 to 626\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   survived            627 non-null    int64  \n",
      " 1   sex                 627 non-null    object \n",
      " 2   age                 627 non-null    float64\n",
      " 3   n_siblings_spouses  627 non-null    int64  \n",
      " 4   parch               627 non-null    int64  \n",
      " 5   fare                627 non-null    float64\n",
      " 6   class               627 non-null    object \n",
      " 7   deck                627 non-null    object \n",
      " 8   embark_town         627 non-null    object \n",
      " 9   alone               627 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 49.1+ KB\n",
      "None\n",
      "         survived         age  n_siblings_spouses       parch        fare\n",
      "count  627.000000  627.000000          627.000000  627.000000  627.000000\n",
      "mean     0.387560   29.631308            0.545455    0.379585   34.385399\n",
      "std      0.487582   12.511818            1.151090    0.792999   54.597730\n",
      "min      0.000000    0.750000            0.000000    0.000000    0.000000\n",
      "25%      0.000000   23.000000            0.000000    0.000000    7.895800\n",
      "50%      0.000000   28.000000            0.000000    0.000000   15.045800\n",
      "75%      1.000000   35.000000            1.000000    0.000000   31.387500\n",
      "max      1.000000   80.000000            8.000000    5.000000  512.329200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived              0\n",
       "sex                   0\n",
       "age                   0\n",
       "n_siblings_spouses    0\n",
       "parch                 0\n",
       "fare                  0\n",
       "class                 0\n",
       "deck                  0\n",
       "embark_town           0\n",
       "alone                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)\n",
    "\n",
    "column_names = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare',\n",
    "       'class', 'deck', 'embark_town', 'alone']\n",
    "\n",
    "df = pd.read_csv(TRAIN_DATA_URL)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "print(df)\n",
    "# 데이터 정보 확인\n",
    "print(df.info())\n",
    "# 수치형 데이터 확인\n",
    "print(df.describe())\n",
    "# 범주형 데이터 확인\n",
    "df.describe(include = np.object_)\n",
    "# 결측치 확인\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcfdce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 6270\n",
      "결측치 수: 0\n",
      "총 인원 수: 627\n",
      "중복된 데이터: 69\n"
     ]
    }
   ],
   "source": [
    "# 데이터 요약\n",
    "\n",
    "print(\"전체 데이터 수:\", df.shape[0] * df.shape[1])\n",
    "print(f\"결측치 수: {df.isnull().sum().sum()}\")\n",
    "print(\"총 인원 수:\", df[\"age\"].count())\n",
    "print(\"중복된 데이터:\",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41f362e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
      "survived\n",
      "##features \n",
      " OrderedDict([('sex', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'male', b'male', b'male', b'male', b'male', b'female', b'male',\n",
      "       b'male', b'male', b'female', b'male', b'male', b'female',\n",
      "       b'female', b'male', b'male', b'female', b'female', b'male',\n",
      "       b'female', b'female', b'female', b'female', b'male', b'female',\n",
      "       b'female', b'female', b'male', b'female', b'female', b'male',\n",
      "       b'male'], dtype=object)>), ('age', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([48., 28., 28., 34., 16., 35., 28., 32., 11., 25., 28., 20., 50.,\n",
      "       30., 20., 28., 52., 23., 40., 38., 35., 40.,  2., 29., 28., 36.,\n",
      "       22., 23., 25., 29., 30., 43.], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int32)>), ('parch', <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 4, 0, 0, 1,\n",
      "       1, 0, 0, 2, 0, 0, 1, 0, 0, 0], dtype=int32)>), ('fare', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([ 76.7292,   0.    ,   7.75  ,   8.05  ,   9.5   ,  83.475 ,\n",
      "         0.    ,   7.75  ,  18.7875, 151.55  ,   7.8542,   7.8542,\n",
      "        26.    ,  21.    ,   8.05  ,  52.    ,  93.5   , 113.275 ,\n",
      "        27.9   ,  80.    ,  53.1   ,  39.    ,  10.4625,  66.6   ,\n",
      "         7.8958,  71.    ,  10.5167,  13.    ,  30.    , 211.3375,\n",
      "         7.8958,   8.05  ], dtype=float32)>), ('class', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'First', b'First', b'Third', b'Third', b'Third', b'First',\n",
      "       b'Second', b'Third', b'Third', b'First', b'Third', b'Third',\n",
      "       b'Second', b'Second', b'Third', b'First', b'First', b'First',\n",
      "       b'Third', b'First', b'First', b'Second', b'Third', b'First',\n",
      "       b'Third', b'First', b'Third', b'Second', b'Second', b'First',\n",
      "       b'Third', b'Third'], dtype=object)>), ('deck', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'D', b'B', b'unknown', b'unknown', b'unknown', b'C', b'unknown',\n",
      "       b'unknown', b'unknown', b'C', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown', b'A', b'B', b'D', b'unknown', b'B', b'C',\n",
      "       b'unknown', b'G', b'C', b'unknown', b'B', b'unknown', b'unknown',\n",
      "       b'unknown', b'B', b'unknown', b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Cherbourg', b'Southampton', b'Queenstown', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Queenstown',\n",
      "       b'Cherbourg', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Cherbourg', b'Southampton', b'unknown',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton'],\n",
      "      dtype=object)>), ('alone', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'n', b'y', b'y', b'y', b'y', b'n', b'y', b'y', b'y', b'n', b'y',\n",
      "       b'y', b'n', b'n', b'y', b'y', b'n', b'n', b'n', b'y', b'n', b'n',\n",
      "       b'n', b'n', b'y', b'n', b'y', b'y', b'n', b'y', b'y', b'y'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "feature_names = column_names[1:]\n",
    "label_name = column_names[0]\n",
    "\n",
    "print(feature_names)\n",
    "print(label_name)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_file_path,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "\n",
    "test_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_file_path,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(f\"##features \\n {features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e231eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features \n",
      " OrderedDict([('sex', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'male', b'female', b'male', b'female', b'female', b'male',\n",
      "       b'male', b'male', b'male', b'male', b'female', b'male', b'male',\n",
      "       b'male', b'male', b'female', b'female', b'male', b'male', b'male',\n",
      "       b'male', b'male', b'male', b'male', b'male', b'female', b'female',\n",
      "       b'male', b'male', b'male', b'female', b'female'], dtype=object)>), ('age', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.3438486 , 0.39432177, 0.3438486 , 0.3438486 , 0.3564669 ,\n",
      "       0.6214511 , 0.36908516, 0.3438486 , 0.44479495, 0.3438486 ,\n",
      "       0.17981073, 0.3438486 , 0.50157726, 0.43217665, 0.07886435,\n",
      "       0.43217665, 0.48264983, 0.5835962 , 0.21766561, 0.31861198,\n",
      "       0.49526814, 0.3438486 , 0.3438486 , 0.39432177, 0.59621453,\n",
      "       0.5835962 , 0.06624606, 0.2933754 , 0.43217665, 0.20504732,\n",
      "       0.3438486 , 0.3438486 ], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([0.   , 0.125, 1.   , 0.   , 0.   , 0.125, 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.   , 0.125, 0.   , 0.   , 0.5  , 0.125, 0.125, 0.   ,\n",
      "       0.   , 0.25 , 0.   , 0.   , 0.125, 0.   , 0.125, 0.125, 0.   ,\n",
      "       0.   , 0.   , 0.   , 0.   , 0.   ])>), ('parch', <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([0. , 0.2, 0.4, 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0.2, 0. , 0. ,\n",
      "       0. , 0.2, 0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. ,\n",
      "       0.2, 0. , 0. , 0. , 0. , 0. ])>), ('fare', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.02937564, 0.03025398, 0.13575256, 0.01410226, 0.04113566,\n",
      "       0.10910953, 0.02049463, 0.01583455, 0.02537431, 0.43288416,\n",
      "       0.4125033 , 0.03025398, 0.01512699, 0.05074862, 0.07746483,\n",
      "       0.16293234, 0.16231419, 0.02927805, 0.01512699, 0.01690807,\n",
      "       0.01541157, 0.01411046, 0.02975782, 0.01541157, 0.14976542,\n",
      "       0.02830211, 0.06441171, 0.01463083, 0.05182214, 0.01690807,\n",
      "       0.02537431, 0.0150944 ], dtype=float32)>), ('class', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Second', b'Third', b'Third', b'Third', b'Third', b'First',\n",
      "       b'Second', b'Third', b'Second', b'First', b'First', b'Third',\n",
      "       b'Third', b'Second', b'Third', b'First', b'First', b'Second',\n",
      "       b'Third', b'Third', b'Third', b'Third', b'Third', b'Third',\n",
      "       b'First', b'Third', b'Second', b'Third', b'First', b'Third',\n",
      "       b'Second', b'Third'], dtype=object)>), ('deck', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', b'unknown', b'unknown', b'E',\n",
      "       b'unknown', b'unknown', b'unknown', b'C', b'B', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown', b'C', b'E', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'D', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown'], dtype=object)>), ('alone', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'y', b'n', b'n', b'y', b'n', b'n', b'y', b'y', b'y', b'y', b'n',\n",
      "       b'n', b'y', b'y', b'n', b'n', b'n', b'y', b'y', b'n', b'y', b'y',\n",
      "       b'n', b'y', b'n', b'n', b'n', b'y', b'y', b'y', b'y', b'y'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "age_max = df['age'].max()\n",
    "age_min = df['age'].min()\n",
    "n_siblings_spouses_max = df['n_siblings_spouses'].max()\n",
    "n_siblings_spouses_min = df['n_siblings_spouses'].min()\n",
    "parch_max = df['parch'].max()\n",
    "parch_min = df['parch'].min()\n",
    "fare_max = df['fare'].max()\n",
    "fare_min = df['fare'].min()\n",
    "\n",
    "\n",
    "# 불필요한 컬럼 삭제 및 데이터 정규화 -> embark_town\n",
    "def transform(features, labels):\n",
    "    features['age'] = (features['age'] - age_min) / (age_max - age_min)\n",
    "    features['n_siblings_spouses'] = (features['n_siblings_spouses'] - n_siblings_spouses_min) / (n_siblings_spouses_max - n_siblings_spouses_min)\n",
    "    features['parch'] = (features['parch'] - parch_min) / (parch_max - parch_min)\n",
    "    features['fare'] = (features['fare'] - fare_min) / (fare_max - fare_min)\n",
    "    del(features['embark_town'])\n",
    "    return features, labels\n",
    "\n",
    "train_dataset = train_dataset.map(transform)\n",
    "test_dataset = test_dataset.map(transform)\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(f\"features \\n {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a94cb176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='n_siblings_spouses', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# 문자열 처리 -> sex, deck, alone, class를 문자열로\n",
    "CAT_COLUMNS = ['sex', 'deck', 'alone', 'class']\n",
    "NUM_COLUMNS = ['age', 'fare', 'n_siblings_spouses', 'parch']\n",
    "\n",
    "feature_cols = []\n",
    "\n",
    "# Create IndicatorColumn for categorical features\n",
    "for feature in CAT_COLUMNS:\n",
    "  vocab = df[feature].unique()\n",
    "  feature_cols.append(tf.feature_column.indicator_column(\n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(feature, vocab)))\n",
    "\n",
    "# Create NumericColumn for numerical features\n",
    "for feature in NUM_COLUMNS:\n",
    "  feature_cols.append(tf.feature_column.numeric_column(feature, dtype=tf.float32))\n",
    "\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44913110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>), ('age', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>), ('parch', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>), ('fare', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>), ('class', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>), ('age', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>), ('parch', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>), ('fare', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>), ('class', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 23:04:17.848302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 2s 26ms/step - loss: 0.6955 - binary_accuracy: 0.4354\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6899 - binary_accuracy: 0.4545\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6847 - binary_accuracy: 0.6284\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6759 - binary_accuracy: 0.7049\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6645 - binary_accuracy: 0.7018\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6542 - binary_accuracy: 0.7018\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6444 - binary_accuracy: 0.7081\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6354 - binary_accuracy: 0.7193\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6266 - binary_accuracy: 0.7225\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6183 - binary_accuracy: 0.7289\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6104 - binary_accuracy: 0.7368\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6022 - binary_accuracy: 0.7480\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5927 - binary_accuracy: 0.7544\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5824 - binary_accuracy: 0.7640\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5718 - binary_accuracy: 0.7703\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5617 - binary_accuracy: 0.7719\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5524 - binary_accuracy: 0.7751\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5432 - binary_accuracy: 0.7719\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5348 - binary_accuracy: 0.7703\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5267 - binary_accuracy: 0.7863\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5189 - binary_accuracy: 0.7959\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5119 - binary_accuracy: 0.7990\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5053 - binary_accuracy: 0.7990\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4994 - binary_accuracy: 0.7990\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4935 - binary_accuracy: 0.8006\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4881 - binary_accuracy: 0.8006\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4830 - binary_accuracy: 0.8022\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.4783 - binary_accuracy: 0.8022\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4743 - binary_accuracy: 0.8022\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4708 - binary_accuracy: 0.8022\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4669 - binary_accuracy: 0.8022\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4639 - binary_accuracy: 0.8022\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4614 - binary_accuracy: 0.8022\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4586 - binary_accuracy: 0.8022\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4564 - binary_accuracy: 0.8022\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4542 - binary_accuracy: 0.8022\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4521 - binary_accuracy: 0.8022\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4505 - binary_accuracy: 0.8022\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4489 - binary_accuracy: 0.8006\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4481 - binary_accuracy: 0.8022\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4467 - binary_accuracy: 0.8022\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4455 - binary_accuracy: 0.8022\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4440 - binary_accuracy: 0.8022\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4434 - binary_accuracy: 0.8022\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4423 - binary_accuracy: 0.8022\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4410 - binary_accuracy: 0.8022\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4404 - binary_accuracy: 0.8022\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4399 - binary_accuracy: 0.8006\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4386 - binary_accuracy: 0.8038\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4382 - binary_accuracy: 0.8006\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4375 - binary_accuracy: 0.8070\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4364 - binary_accuracy: 0.8054\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4357 - binary_accuracy: 0.8070\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4348 - binary_accuracy: 0.8038\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4340 - binary_accuracy: 0.8070\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4335 - binary_accuracy: 0.8054\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4330 - binary_accuracy: 0.8054\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4321 - binary_accuracy: 0.8086\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4320 - binary_accuracy: 0.8086\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4311 - binary_accuracy: 0.8086\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4307 - binary_accuracy: 0.8102\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4305 - binary_accuracy: 0.8102\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4292 - binary_accuracy: 0.8150\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4285 - binary_accuracy: 0.8118\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4279 - binary_accuracy: 0.8134\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4273 - binary_accuracy: 0.8150\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4270 - binary_accuracy: 0.8134\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4261 - binary_accuracy: 0.8102\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4260 - binary_accuracy: 0.8166\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4257 - binary_accuracy: 0.8166\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4249 - binary_accuracy: 0.8214\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4245 - binary_accuracy: 0.8246\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4244 - binary_accuracy: 0.8214\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4238 - binary_accuracy: 0.8262\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4232 - binary_accuracy: 0.8198\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4233 - binary_accuracy: 0.8230\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4229 - binary_accuracy: 0.8262\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4225 - binary_accuracy: 0.8246\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4221 - binary_accuracy: 0.8293\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4219 - binary_accuracy: 0.8262\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4213 - binary_accuracy: 0.8262\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4213 - binary_accuracy: 0.8278\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4211 - binary_accuracy: 0.8341\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4205 - binary_accuracy: 0.8246\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4204 - binary_accuracy: 0.8325\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4204 - binary_accuracy: 0.8278\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4204 - binary_accuracy: 0.8278\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4193 - binary_accuracy: 0.8341\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4189 - binary_accuracy: 0.8278\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4197 - binary_accuracy: 0.8325\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4190 - binary_accuracy: 0.8325\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4187 - binary_accuracy: 0.8309\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4186 - binary_accuracy: 0.8293\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4190 - binary_accuracy: 0.8357\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4177 - binary_accuracy: 0.8309\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4178 - binary_accuracy: 0.8341\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4180 - binary_accuracy: 0.8293\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4170 - binary_accuracy: 0.8357\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4173 - binary_accuracy: 0.8309\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4166 - binary_accuracy: 0.8357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f7cc340>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.DenseFeatures(feature_cols))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(train_dataset, epochs=100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60687f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>), ('age', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float64>), ('parch', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>), ('fare', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>), ('class', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 23:04:42.480479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.58731997],\n",
       "       [0.7441584 ],\n",
       "       [0.12575173],\n",
       "       [0.1218008 ],\n",
       "       [0.11045069],\n",
       "       [0.10860484],\n",
       "       [0.10928388],\n",
       "       [0.10934852],\n",
       "       [0.2952905 ],\n",
       "       [0.91014296],\n",
       "       [0.46740618],\n",
       "       [0.8543506 ],\n",
       "       [0.12125544],\n",
       "       [0.9263537 ],\n",
       "       [0.4676793 ],\n",
       "       [0.8539536 ],\n",
       "       [0.46751022],\n",
       "       [0.90712965],\n",
       "       [0.10865665],\n",
       "       [0.10924384],\n",
       "       [0.11004953],\n",
       "       [0.3678554 ],\n",
       "       [0.12717405],\n",
       "       [0.10940309],\n",
       "       [0.12078246],\n",
       "       [0.86317945],\n",
       "       [0.10968216],\n",
       "       [0.89505965],\n",
       "       [0.12676176],\n",
       "       [0.9424716 ],\n",
       "       [0.10779478],\n",
       "       [0.1154998 ],\n",
       "       [0.92956096],\n",
       "       [0.17661929],\n",
       "       [0.12717405],\n",
       "       [0.70610017],\n",
       "       [0.16169126],\n",
       "       [0.9245759 ],\n",
       "       [0.1095496 ],\n",
       "       [0.19135894],\n",
       "       [0.11001623],\n",
       "       [0.40158287],\n",
       "       [0.10973606],\n",
       "       [0.19797698],\n",
       "       [0.13960436],\n",
       "       [0.92257917],\n",
       "       [0.91637754],\n",
       "       [0.12248552],\n",
       "       [0.10928347],\n",
       "       [0.10897308],\n",
       "       [0.91776913],\n",
       "       [0.6293549 ],\n",
       "       [0.8782292 ],\n",
       "       [0.10936347],\n",
       "       [0.6498015 ],\n",
       "       [0.1059433 ],\n",
       "       [0.9677738 ],\n",
       "       [0.10813716],\n",
       "       [0.10931151],\n",
       "       [0.10934852],\n",
       "       [0.9342319 ],\n",
       "       [0.8829164 ],\n",
       "       [0.12170978],\n",
       "       [0.94434786],\n",
       "       [0.10928588],\n",
       "       [0.9459021 ],\n",
       "       [0.92583084],\n",
       "       [0.10871413],\n",
       "       [0.9328735 ],\n",
       "       [0.10934852],\n",
       "       [0.10936347],\n",
       "       [0.3729886 ],\n",
       "       [0.11162686],\n",
       "       [0.10989799],\n",
       "       [0.92140347],\n",
       "       [0.3874894 ],\n",
       "       [0.10953467],\n",
       "       [0.8816292 ],\n",
       "       [0.11534595],\n",
       "       [0.12087715],\n",
       "       [0.10256385],\n",
       "       [0.109516  ],\n",
       "       [0.1101765 ],\n",
       "       [0.7178869 ],\n",
       "       [0.12920651],\n",
       "       [0.2811688 ],\n",
       "       [0.91643834],\n",
       "       [0.10896299],\n",
       "       [0.6385907 ],\n",
       "       [0.9259547 ],\n",
       "       [0.18911391],\n",
       "       [0.3016734 ],\n",
       "       [0.12110925],\n",
       "       [0.92035514],\n",
       "       [0.10909814],\n",
       "       [0.89219964],\n",
       "       [0.42346102],\n",
       "       [0.10941118],\n",
       "       [0.10802078],\n",
       "       [0.12631679],\n",
       "       [0.37539184],\n",
       "       [0.69242084],\n",
       "       [0.10984281],\n",
       "       [0.1235355 ],\n",
       "       [0.4515648 ],\n",
       "       [0.12624802],\n",
       "       [0.11022449],\n",
       "       [0.5226196 ],\n",
       "       [0.12621422],\n",
       "       [0.11027215],\n",
       "       [0.41712898],\n",
       "       [0.5237589 ],\n",
       "       [0.10934448],\n",
       "       [0.31431168],\n",
       "       [0.10984482],\n",
       "       [0.898974  ],\n",
       "       [0.10933276],\n",
       "       [0.4177372 ],\n",
       "       [0.93351805],\n",
       "       [0.5877276 ],\n",
       "       [0.16195567],\n",
       "       [0.10925681],\n",
       "       [0.17128763],\n",
       "       [0.28102267],\n",
       "       [0.97300875],\n",
       "       [0.90054536],\n",
       "       [0.34685528],\n",
       "       [0.11005363],\n",
       "       [0.10933441],\n",
       "       [0.48305237],\n",
       "       [0.12703693],\n",
       "       [0.10665431],\n",
       "       [0.9061311 ],\n",
       "       [0.5593085 ],\n",
       "       [0.3673446 ],\n",
       "       [0.93564653],\n",
       "       [0.8986865 ],\n",
       "       [0.51889074],\n",
       "       [0.12047056],\n",
       "       [0.40340754],\n",
       "       [0.46951205],\n",
       "       [0.10928347],\n",
       "       [0.12397902],\n",
       "       [0.87021095],\n",
       "       [0.5714142 ],\n",
       "       [0.6678074 ],\n",
       "       [0.5190641 ],\n",
       "       [0.12056894],\n",
       "       [0.10623051],\n",
       "       [0.68656874],\n",
       "       [0.2262406 ],\n",
       "       [0.31570715],\n",
       "       [0.92991143],\n",
       "       [0.93045723],\n",
       "       [0.5136418 ],\n",
       "       [0.2886142 ],\n",
       "       [0.10961287],\n",
       "       [0.17280605],\n",
       "       [0.10770603],\n",
       "       [0.10933441],\n",
       "       [0.91695243],\n",
       "       [0.44345   ],\n",
       "       [0.7255026 ],\n",
       "       [0.10700964],\n",
       "       [0.88290113],\n",
       "       [0.16402243],\n",
       "       [0.8770692 ],\n",
       "       [0.10934852],\n",
       "       [0.69799924],\n",
       "       [0.10488968],\n",
       "       [0.11189463],\n",
       "       [0.10936347],\n",
       "       [0.10813091],\n",
       "       [0.27633265],\n",
       "       [0.10936347],\n",
       "       [0.09761388],\n",
       "       [0.700593  ],\n",
       "       [0.27903727],\n",
       "       [0.11007595],\n",
       "       [0.12646382],\n",
       "       [0.19036855],\n",
       "       [0.11027014],\n",
       "       [0.10986052],\n",
       "       [0.41491744],\n",
       "       [0.10902224],\n",
       "       [0.48356518],\n",
       "       [0.10944157],\n",
       "       [0.1100154 ],\n",
       "       [0.47059762],\n",
       "       [0.12661693],\n",
       "       [0.11048453],\n",
       "       [0.5130069 ],\n",
       "       [0.10929195],\n",
       "       [0.57056254],\n",
       "       [0.10928347],\n",
       "       [0.10981437],\n",
       "       [0.5496109 ],\n",
       "       [0.10931497],\n",
       "       [0.1092479 ],\n",
       "       [0.9278853 ],\n",
       "       [0.9075824 ],\n",
       "       [0.10563043],\n",
       "       [0.11030029],\n",
       "       [0.9082584 ],\n",
       "       [0.9291774 ],\n",
       "       [0.8709776 ],\n",
       "       [0.47213566],\n",
       "       [0.10869926],\n",
       "       [0.9593649 ],\n",
       "       [0.8868077 ],\n",
       "       [0.525364  ],\n",
       "       [0.10335855],\n",
       "       [0.34553742],\n",
       "       [0.12213664],\n",
       "       [0.10933238],\n",
       "       [0.28002882],\n",
       "       [0.5515979 ],\n",
       "       [0.16159272],\n",
       "       [0.3673521 ],\n",
       "       [0.12511323],\n",
       "       [0.12823026],\n",
       "       [0.45573598],\n",
       "       [0.12604302],\n",
       "       [0.6904444 ],\n",
       "       [0.5092182 ],\n",
       "       [0.11045069],\n",
       "       [0.10738602],\n",
       "       [0.40340754],\n",
       "       [0.702108  ],\n",
       "       [0.12674741],\n",
       "       [0.5158486 ],\n",
       "       [0.89311314],\n",
       "       [0.12583826],\n",
       "       [0.10934852],\n",
       "       [0.33608082],\n",
       "       [0.11962445],\n",
       "       [0.11428271],\n",
       "       [0.9341761 ],\n",
       "       [0.12393545],\n",
       "       [0.3764898 ],\n",
       "       [0.49194923],\n",
       "       [0.12416404],\n",
       "       [0.5140059 ],\n",
       "       [0.10954559],\n",
       "       [0.12314344],\n",
       "       [0.6980704 ],\n",
       "       [0.11008844],\n",
       "       [0.10981033],\n",
       "       [0.12723166],\n",
       "       [0.7377396 ],\n",
       "       [0.16169126],\n",
       "       [0.35577416],\n",
       "       [0.10934852],\n",
       "       [0.12137687],\n",
       "       [0.9749    ],\n",
       "       [0.12631679],\n",
       "       [0.36837083],\n",
       "       [0.966331  ],\n",
       "       [0.10928388],\n",
       "       [0.07811664],\n",
       "       [0.6573858 ],\n",
       "       [0.10936347],\n",
       "       [0.11028516],\n",
       "       [0.12908448],\n",
       "       [0.10933441],\n",
       "       [0.94409585],\n",
       "       [0.13633491],\n",
       "       [0.44602576],\n",
       "       [0.11946733],\n",
       "       [0.40340754],\n",
       "       [0.90420324],\n",
       "       [0.2564106 ],\n",
       "       [0.9441281 ],\n",
       "       [0.9099766 ],\n",
       "       [0.10962784],\n",
       "       [0.10903956],\n",
       "       [0.4294909 ],\n",
       "       [0.95213646],\n",
       "       [0.4971424 ],\n",
       "       [0.1088067 ],\n",
       "       [0.12510197],\n",
       "       [0.5140059 ],\n",
       "       [0.1099894 ],\n",
       "       [0.11059741],\n",
       "       [0.6977451 ],\n",
       "       [0.10933882],\n",
       "       [0.10897709],\n",
       "       [0.19605899],\n",
       "       [0.11002969],\n",
       "       [0.92705333],\n",
       "       [0.7475674 ],\n",
       "       [0.9271602 ],\n",
       "       [0.07811664],\n",
       "       [0.10936347],\n",
       "       [0.11035375],\n",
       "       [0.10905817],\n",
       "       [0.12510197],\n",
       "       [0.10934852],\n",
       "       [0.47994164],\n",
       "       [0.92092174],\n",
       "       [0.09668303],\n",
       "       [0.10953386],\n",
       "       [0.8724855 ],\n",
       "       [0.10936958],\n",
       "       [0.9033092 ],\n",
       "       [0.88770425],\n",
       "       [0.11025136],\n",
       "       [0.37146702],\n",
       "       [0.94696915],\n",
       "       [0.10999144],\n",
       "       [0.11994404],\n",
       "       [0.10710392],\n",
       "       [0.8607654 ],\n",
       "       [0.1095043 ],\n",
       "       [0.12542967],\n",
       "       [0.10990772],\n",
       "       [0.3695053 ],\n",
       "       [0.7216818 ],\n",
       "       [0.10923743],\n",
       "       [0.7216702 ],\n",
       "       [0.10913119],\n",
       "       [0.1622633 ],\n",
       "       [0.10954559],\n",
       "       [0.57363176],\n",
       "       [0.91532665],\n",
       "       [0.74347425],\n",
       "       [0.91485435],\n",
       "       [0.21449314],\n",
       "       [0.10933682],\n",
       "       [0.47856894],\n",
       "       [0.09884363],\n",
       "       [0.47372326],\n",
       "       [0.1079074 ],\n",
       "       [0.12636757],\n",
       "       [0.40668696],\n",
       "       [0.1268308 ],\n",
       "       [0.24151261],\n",
       "       [0.69806224],\n",
       "       [0.10916268],\n",
       "       [0.3807531 ],\n",
       "       [0.9168029 ],\n",
       "       [0.11434663],\n",
       "       [0.92249334],\n",
       "       [0.12335908],\n",
       "       [0.10934852],\n",
       "       [0.32256562],\n",
       "       [0.12703693],\n",
       "       [0.6979911 ],\n",
       "       [0.10934208],\n",
       "       [0.10928388],\n",
       "       [0.94013095],\n",
       "       [0.10934852],\n",
       "       [0.36531764],\n",
       "       [0.91268367],\n",
       "       [0.11041066],\n",
       "       [0.29075277],\n",
       "       [0.11009065],\n",
       "       [0.07811664],\n",
       "       [0.9446785 ],\n",
       "       [0.40953445],\n",
       "       [0.10936347],\n",
       "       [0.92056715],\n",
       "       [0.6290523 ],\n",
       "       [0.1261001 ],\n",
       "       [0.40236825],\n",
       "       [0.53251976],\n",
       "       [0.57056254],\n",
       "       [0.9372687 ],\n",
       "       [0.35868523],\n",
       "       [0.11000404],\n",
       "       [0.10934852],\n",
       "       [0.22998387],\n",
       "       [0.11032145],\n",
       "       [0.13249603],\n",
       "       [0.36499378],\n",
       "       [0.9652283 ],\n",
       "       [0.11021393],\n",
       "       [0.12681918],\n",
       "       [0.44673723],\n",
       "       [0.9510203 ],\n",
       "       [0.6237089 ],\n",
       "       [0.71771115],\n",
       "       [0.7840555 ],\n",
       "       [0.87848145],\n",
       "       [0.5178122 ],\n",
       "       [0.1213164 ],\n",
       "       [0.10771576],\n",
       "       [0.12103927],\n",
       "       [0.12510197],\n",
       "       [0.9600424 ],\n",
       "       [0.9222639 ],\n",
       "       [0.9662277 ],\n",
       "       [0.12539609],\n",
       "       [0.28427294],\n",
       "       [0.10831656],\n",
       "       [0.846962  ],\n",
       "       [0.5136418 ],\n",
       "       [0.5446592 ],\n",
       "       [0.9434493 ],\n",
       "       [0.12510197],\n",
       "       [0.12726244],\n",
       "       [0.69799924],\n",
       "       [0.10897993],\n",
       "       [0.69799924],\n",
       "       [0.12125544],\n",
       "       [0.10759529],\n",
       "       [0.10368321],\n",
       "       [0.17118305],\n",
       "       [0.11048453],\n",
       "       [0.11059884],\n",
       "       [0.909736  ],\n",
       "       [0.10936347],\n",
       "       [0.49053082],\n",
       "       [0.10926651],\n",
       "       [0.9260182 ],\n",
       "       [0.69799924],\n",
       "       [0.2516961 ],\n",
       "       [0.11010976],\n",
       "       [0.1231652 ],\n",
       "       [0.69801754],\n",
       "       [0.10964767],\n",
       "       [0.50157255],\n",
       "       [0.9339299 ],\n",
       "       [0.27954018],\n",
       "       [0.10861766],\n",
       "       [0.36371967],\n",
       "       [0.8770692 ],\n",
       "       [0.10936347],\n",
       "       [0.1088067 ],\n",
       "       [0.12652218],\n",
       "       [0.09730857],\n",
       "       [0.6260088 ],\n",
       "       [0.90952194],\n",
       "       [0.9250216 ],\n",
       "       [0.9221941 ],\n",
       "       [0.1095043 ],\n",
       "       [0.9088429 ],\n",
       "       [0.6861351 ],\n",
       "       [0.1273877 ],\n",
       "       [0.10933682],\n",
       "       [0.9461987 ],\n",
       "       [0.94122064],\n",
       "       [0.5337335 ],\n",
       "       [0.10998496],\n",
       "       [0.92008835],\n",
       "       [0.10819533],\n",
       "       [0.10856168],\n",
       "       [0.40655422],\n",
       "       [0.30853602],\n",
       "       [0.9086661 ],\n",
       "       [0.12570235],\n",
       "       [0.10953467],\n",
       "       [0.12553175],\n",
       "       [0.12892339],\n",
       "       [0.12797742],\n",
       "       [0.89646584],\n",
       "       [0.6632011 ],\n",
       "       [0.9663304 ],\n",
       "       [0.10231459],\n",
       "       [0.5314549 ],\n",
       "       [0.10934852],\n",
       "       [0.94378316],\n",
       "       [0.162204  ],\n",
       "       [0.1217315 ],\n",
       "       [0.93369913],\n",
       "       [0.1374107 ],\n",
       "       [0.12645334],\n",
       "       [0.5826427 ],\n",
       "       [0.11020332],\n",
       "       [0.10983264],\n",
       "       [0.12549728],\n",
       "       [0.10934852],\n",
       "       [0.12755342],\n",
       "       [0.11062659],\n",
       "       [0.6979016 ],\n",
       "       [0.91633433],\n",
       "       [0.11415341],\n",
       "       [0.5193527 ],\n",
       "       [0.8937968 ],\n",
       "       [0.4856526 ],\n",
       "       [0.10557152],\n",
       "       [0.9134367 ],\n",
       "       [0.16228186],\n",
       "       [0.89832383],\n",
       "       [0.12510197],\n",
       "       [0.19778466],\n",
       "       [0.36371967],\n",
       "       [0.12806001],\n",
       "       [0.16259266],\n",
       "       [0.28896245],\n",
       "       [0.10760377],\n",
       "       [0.10796049],\n",
       "       [0.12549368],\n",
       "       [0.4522348 ],\n",
       "       [0.28531593],\n",
       "       [0.18895243],\n",
       "       [0.10928588],\n",
       "       [0.9228403 ],\n",
       "       [0.1095229 ],\n",
       "       [0.10909772],\n",
       "       [0.39507008],\n",
       "       [0.10933441],\n",
       "       [0.11001217],\n",
       "       [0.57144904],\n",
       "       [0.121291  ],\n",
       "       [0.10934852],\n",
       "       [0.7441657 ],\n",
       "       [0.11376773],\n",
       "       [0.36807323],\n",
       "       [0.57393867],\n",
       "       [0.90524477],\n",
       "       [0.11415341],\n",
       "       [0.5600555 ],\n",
       "       [0.9227433 ],\n",
       "       [0.9416629 ],\n",
       "       [0.11007643],\n",
       "       [0.4780799 ],\n",
       "       [0.10940959],\n",
       "       [0.10933441],\n",
       "       [0.12029656],\n",
       "       [0.10998534],\n",
       "       [0.91260445],\n",
       "       [0.91140884],\n",
       "       [0.93664306],\n",
       "       [0.3907844 ],\n",
       "       [0.9529247 ],\n",
       "       [0.93226075],\n",
       "       [0.1345988 ],\n",
       "       [0.07811664],\n",
       "       [0.10999085],\n",
       "       [0.10654312],\n",
       "       [0.12539609],\n",
       "       [0.851375  ],\n",
       "       [0.1259069 ],\n",
       "       [0.12131485],\n",
       "       [0.69799924],\n",
       "       [0.11201414],\n",
       "       [0.16212527],\n",
       "       [0.69799924],\n",
       "       [0.10972106],\n",
       "       [0.16246499],\n",
       "       [0.92350066],\n",
       "       [0.17850293],\n",
       "       [0.49238178],\n",
       "       [0.91569984],\n",
       "       [0.3451681 ],\n",
       "       [0.10895776],\n",
       "       [0.10941947],\n",
       "       [0.39761096],\n",
       "       [0.12479933],\n",
       "       [0.10897993],\n",
       "       [0.10936347],\n",
       "       [0.10862488],\n",
       "       [0.11026771],\n",
       "       [0.8960594 ],\n",
       "       [0.10992277],\n",
       "       [0.12748405],\n",
       "       [0.10984482],\n",
       "       [0.5294301 ],\n",
       "       [0.30056798],\n",
       "       [0.12652218],\n",
       "       [0.55142397],\n",
       "       [0.41061082],\n",
       "       [0.86555815],\n",
       "       [0.10742902],\n",
       "       [0.29247633],\n",
       "       [0.40608403],\n",
       "       [0.10570226],\n",
       "       [0.10886245],\n",
       "       [0.10934852],\n",
       "       [0.10829913],\n",
       "       [0.9204821 ],\n",
       "       [0.1101883 ],\n",
       "       [0.10696212],\n",
       "       [0.93342537],\n",
       "       [0.11415341],\n",
       "       [0.85007656],\n",
       "       [0.10859995],\n",
       "       [0.12594059],\n",
       "       [0.10933441],\n",
       "       [0.2595683 ],\n",
       "       [0.3645393 ],\n",
       "       [0.46262977],\n",
       "       [0.42747444],\n",
       "       [0.946134  ],\n",
       "       [0.10934852],\n",
       "       [0.12031125],\n",
       "       [0.10933194],\n",
       "       [0.1101883 ],\n",
       "       [0.94698715],\n",
       "       [0.9092711 ],\n",
       "       [0.5487855 ],\n",
       "       [0.90978867],\n",
       "       [0.69806224],\n",
       "       [0.34973344],\n",
       "       [0.10612886],\n",
       "       [0.5136418 ],\n",
       "       [0.1078454 ],\n",
       "       [0.69814557],\n",
       "       [0.12248552],\n",
       "       [0.18146269],\n",
       "       [0.12693383],\n",
       "       [0.89839745],\n",
       "       [0.3867006 ],\n",
       "       [0.10887275],\n",
       "       [0.6977429 ],\n",
       "       [0.57239306],\n",
       "       [0.72295517],\n",
       "       [0.10942297],\n",
       "       [0.1268308 ],\n",
       "       [0.12427856],\n",
       "       [0.39310366],\n",
       "       [0.7514386 ],\n",
       "       [0.10933441],\n",
       "       [0.19778466],\n",
       "       [0.16191974],\n",
       "       [0.9317726 ],\n",
       "       [0.22929181],\n",
       "       [0.13406801],\n",
       "       [0.11598458],\n",
       "       [0.12592998],\n",
       "       [0.10925557],\n",
       "       [0.11415341],\n",
       "       [0.69806224],\n",
       "       [0.37171018],\n",
       "       [0.5248901 ],\n",
       "       [0.16240175]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "model.predict(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_everyone",
   "language": "python",
   "name": "ml_for_everyone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
