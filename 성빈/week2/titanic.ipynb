{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d187e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fdd7348d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0           0    male  22.0                   1      0   7.2500   Third   \n",
      "1           1  female  38.0                   1      0  71.2833   First   \n",
      "2           1  female  26.0                   0      0   7.9250   Third   \n",
      "3           1  female  35.0                   1      0  53.1000   First   \n",
      "4           0    male  28.0                   0      0   8.4583   Third   \n",
      "..        ...     ...   ...                 ...    ...      ...     ...   \n",
      "622         0    male  28.0                   0      0  10.5000  Second   \n",
      "623         0    male  25.0                   0      0   7.0500   Third   \n",
      "624         1  female  19.0                   0      0  30.0000   First   \n",
      "625         0  female  28.0                   1      2  23.4500   Third   \n",
      "626         0    male  32.0                   0      0   7.7500   Third   \n",
      "\n",
      "        deck  embark_town alone  \n",
      "0    unknown  Southampton     n  \n",
      "1          C    Cherbourg     n  \n",
      "2    unknown  Southampton     y  \n",
      "3          C  Southampton     n  \n",
      "4    unknown   Queenstown     y  \n",
      "..       ...          ...   ...  \n",
      "622  unknown  Southampton     y  \n",
      "623  unknown  Southampton     y  \n",
      "624        B  Southampton     y  \n",
      "625  unknown  Southampton     n  \n",
      "626  unknown   Queenstown     y  \n",
      "\n",
      "[627 rows x 10 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 627 entries, 0 to 626\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   survived            627 non-null    int64  \n",
      " 1   sex                 627 non-null    object \n",
      " 2   age                 627 non-null    float64\n",
      " 3   n_siblings_spouses  627 non-null    int64  \n",
      " 4   parch               627 non-null    int64  \n",
      " 5   fare                627 non-null    float64\n",
      " 6   class               627 non-null    object \n",
      " 7   deck                627 non-null    object \n",
      " 8   embark_town         627 non-null    object \n",
      " 9   alone               627 non-null    object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 49.1+ KB\n",
      "None\n",
      "         survived         age  n_siblings_spouses       parch        fare\n",
      "count  627.000000  627.000000          627.000000  627.000000  627.000000\n",
      "mean     0.387560   29.631308            0.545455    0.379585   34.385399\n",
      "std      0.487582   12.511818            1.151090    0.792999   54.597730\n",
      "min      0.000000    0.750000            0.000000    0.000000    0.000000\n",
      "25%      0.000000   23.000000            0.000000    0.000000    7.895800\n",
      "50%      0.000000   28.000000            0.000000    0.000000   15.045800\n",
      "75%      1.000000   35.000000            1.000000    0.000000   31.387500\n",
      "max      1.000000   80.000000            8.000000    5.000000  512.329200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "survived              0\n",
       "sex                   0\n",
       "age                   0\n",
       "n_siblings_spouses    0\n",
       "parch                 0\n",
       "fare                  0\n",
       "class                 0\n",
       "deck                  0\n",
       "embark_town           0\n",
       "alone                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)\n",
    "\n",
    "column_names = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare',\n",
    "       'class', 'deck', 'embark_town', 'alone']\n",
    "\n",
    "df = pd.read_csv(TRAIN_DATA_URL)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "print(df)\n",
    "# 데이터 정보 확인\n",
    "print(df.info())\n",
    "# 수치형 데이터 확인\n",
    "print(df.describe())\n",
    "# 범주형 데이터 확인\n",
    "df.describe(include = np.object_)\n",
    "# 결측치 확인\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fcfdce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 6270\n",
      "결측치 수: 0\n",
      "총 인원 수: 627\n",
      "중복된 데이터: 69\n"
     ]
    }
   ],
   "source": [
    "# 데이터 요약\n",
    "\n",
    "print(\"전체 데이터 수:\", df.shape[0] * df.shape[1])\n",
    "print(f\"결측치 수: {df.isnull().sum().sum()}\")\n",
    "print(\"총 인원 수:\", df[\"age\"].count())\n",
    "print(\"중복된 데이터:\",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d41f362e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
      "survived\n",
      "##features \n",
      " OrderedDict([('sex', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'male', b'male', b'male', b'male', b'female', b'female', b'male',\n",
      "       b'female', b'male', b'male', b'female', b'female', b'female',\n",
      "       b'female', b'male', b'female', b'female', b'male', b'female',\n",
      "       b'male', b'male', b'male', b'female', b'male', b'male', b'male',\n",
      "       b'male', b'male', b'male', b'female', b'male', b'male'],\n",
      "      dtype=object)>), ('age', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([28.  , 38.  , 26.  , 34.5 , 39.  , 17.  , 23.  , 27.  , 57.  ,\n",
      "        0.83, 28.  , 50.  , 19.  , 14.  , 28.  , 28.  , 22.  , 40.5 ,\n",
      "       44.  , 27.  , 51.  ,  1.  , 28.  , 18.  , 29.  , 20.  , 33.  ,\n",
      "       26.  , 40.  , 60.  , 28.  , 30.5 ], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4,\n",
      "       0, 0, 0, 0, 1, 2, 0, 1, 1, 0], dtype=int32)>), ('parch', <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 1, 0, 0, 5, 0, 0, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int32)>), ('fare', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([  7.775 , 153.4625,   7.8958,   6.4375,  31.275 ,  12.    ,\n",
      "         7.8958,   7.925 ,  12.35  ,  29.    ,  23.45  ,  26.    ,\n",
      "        26.2833,   7.8542,  82.1708,   7.75  , 151.55  ,   7.75  ,\n",
      "        57.9792,  26.    ,   8.05  ,  39.6875,   7.8958,  11.5   ,\n",
      "         9.5   ,   9.5   ,  20.525 ,   8.6625,  27.7208,  75.25  ,\n",
      "        15.5   ,   8.05  ], dtype=float32)>), ('class', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Third', b'First', b'Third', b'Third', b'Third', b'Second',\n",
      "       b'Third', b'Third', b'Second', b'Second', b'Third', b'Second',\n",
      "       b'First', b'Third', b'First', b'Third', b'First', b'Third',\n",
      "       b'First', b'Second', b'Third', b'Third', b'Third', b'Second',\n",
      "       b'Third', b'Third', b'Third', b'Third', b'First', b'First',\n",
      "       b'Third', b'Third'], dtype=object)>), ('deck', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'unknown', b'C', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'D', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'B', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'D', b'unknown', b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Southampton', b'Cherbourg', b'Southampton', b'Southampton',\n",
      "       b'Queenstown', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Cherbourg', b'Queenstown',\n",
      "       b'Southampton', b'Queenstown', b'Cherbourg', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Cherbourg', b'Cherbourg', b'Queenstown', b'Southampton'],\n",
      "      dtype=object)>), ('alone', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'y', b'n', b'y', b'y', b'n', b'y', b'y', b'y', b'y', b'n', b'n',\n",
      "       b'n', b'n', b'y', b'n', b'y', b'y', b'y', b'n', b'y', b'y', b'n',\n",
      "       b'y', b'y', b'y', b'y', b'n', b'n', b'y', b'n', b'n', b'y'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "feature_names = column_names[1:]\n",
    "label_name = column_names[0]\n",
    "\n",
    "print(feature_names)\n",
    "print(label_name)\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_file_path,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "\n",
    "test_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_file_path,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "\n",
    "\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(f\"##features \\n {features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0901cdc6-cd41-4872-9322-96cc2a0b14c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shuffle\n",
    "train_dataset = train_dataset.shuffle(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e231eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features \n",
      " OrderedDict([('sex', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'male', b'male', b'male', b'female', b'female', b'male', b'male',\n",
      "       b'female', b'male', b'female', b'male', b'male', b'female',\n",
      "       b'female', b'male', b'male', b'male', b'female', b'female',\n",
      "       b'male', b'male', b'female', b'male', b'male', b'male', b'male',\n",
      "       b'male', b'male', b'female', b'male', b'male', b'male'],\n",
      "      dtype=object)>), ('age', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.49526814, 0.2933754 , 0.6214511 , 0.72239745, 0.3438486 ,\n",
      "       0.3438486 , 0.3438486 , 0.3438486 , 0.43217665, 0.43217665,\n",
      "       0.533123  , 0.30599368, 0.6466877 , 0.6214511 , 0.5709779 ,\n",
      "       0.00315457, 0.3438486 , 0.5078864 , 0.20504732, 0.31861198,\n",
      "       0.2681388 , 0.38170347, 0.35015774, 0.3438486 , 0.3438486 ,\n",
      "       0.5205047 , 0.24921136, 0.3438486 , 0.3438486 , 0.3438486 ,\n",
      "       0.38170347, 0.23028392], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([0.   , 0.   , 0.25 , 0.   , 0.125, 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.125, 0.125, 0.125, 0.   , 0.125, 0.5  , 0.   , 0.   ,\n",
      "       0.125, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
      "       0.   , 0.25 , 0.   , 0.125, 0.   ])>), ('parch', <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0. , 0. ,\n",
      "       0. , 0. , 0.2, 0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
      "       0. , 0. , 0. , 0. , 0.2, 0. ])>), ('fare', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([0.01541157, 0.01541157, 0.26086742, 0.29953882, 0.03025398,\n",
      "       0.01512699, 0.01571255, 0.02537431, 1.        , 0.26473856,\n",
      "       0.05123658, 0.01517579, 0.15276642, 0.05604307, 0.11940564,\n",
      "       0.07746483, 0.06050797, 0.03806146, 0.11125658, 0.01539537,\n",
      "       0.01541157, 0.01694867, 0.01411046, 0.01583455, 0.05953203,\n",
      "       0.01473662, 0.01415106, 0.01541157, 0.04538098, 0.01541157,\n",
      "       0.07222738, 0.01517579], dtype=float32)>), ('class', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Third', b'Third', b'First', b'First', b'Third', b'Third',\n",
      "       b'Third', b'Second', b'First', b'First', b'Second', b'Third',\n",
      "       b'First', b'First', b'First', b'Third', b'First', b'Second',\n",
      "       b'First', b'Third', b'Third', b'Third', b'Third', b'Third',\n",
      "       b'First', b'Third', b'Third', b'Third', b'Third', b'Third',\n",
      "       b'Second', b'Third'], dtype=object)>), ('deck', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', b'C', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown', b'B', b'C', b'unknown', b'unknown', b'D',\n",
      "       b'C', b'E', b'unknown', b'unknown', b'unknown', b'B', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown', b'unknown', b'C', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Queenstown', b'Queenstown', b'Southampton', b'Southampton',\n",
      "       b'Cherbourg', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Cherbourg', b'Cherbourg', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Cherbourg', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Queenstown', b'Southampton', b'Cherbourg', b'Southampton'],\n",
      "      dtype=object)>), ('alone', <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'y', b'y', b'n', b'n', b'n', b'y', b'y', b'y', b'y', b'y', b'n',\n",
      "       b'n', b'n', b'y', b'n', b'n', b'y', b'n', b'n', b'y', b'y', b'y',\n",
      "       b'y', b'y', b'y', b'y', b'y', b'y', b'n', b'y', b'n', b'y'],\n",
      "      dtype=object)>)])\n"
     ]
    }
   ],
   "source": [
    "age_max = df['age'].max()\n",
    "age_min = df['age'].min()\n",
    "n_siblings_spouses_max = df['n_siblings_spouses'].max()\n",
    "n_siblings_spouses_min = df['n_siblings_spouses'].min()\n",
    "parch_max = df['parch'].max()\n",
    "parch_min = df['parch'].min()\n",
    "fare_max = df['fare'].max()\n",
    "fare_min = df['fare'].min()\n",
    "\n",
    "\n",
    "# 데이터 정규화\n",
    "def normalization(features, labels):\n",
    "    features['age'] = (features['age'] - age_min) / (age_max - age_min)\n",
    "    features['n_siblings_spouses'] = (features['n_siblings_spouses'] - n_siblings_spouses_min) / (n_siblings_spouses_max - n_siblings_spouses_min)\n",
    "    features['parch'] = (features['parch'] - parch_min) / (parch_max - parch_min)\n",
    "    features['fare'] = (features['fare'] - fare_min) / (fare_max - fare_min)\n",
    "    return features, labels\n",
    "\n",
    "train_dataset = train_dataset.map(normalization)\n",
    "test_dataset = test_dataset.map(normalization)\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(f\"features \\n {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a94cb176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='n_siblings_spouses', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# 문자열 처리 -> sex, deck, alone, class를 문자열로\n",
    "CAT_COLUMNS = ['sex', 'deck', 'alone', 'class', 'embark_town']\n",
    "NUM_COLUMNS = ['age', 'fare', 'n_siblings_spouses', 'parch']\n",
    "\n",
    "feature_cols = []\n",
    "\n",
    "# Create IndicatorColumn for categorical features\n",
    "for feature in CAT_COLUMNS:\n",
    "  vocab = df[feature].unique()\n",
    "  feature_cols.append(tf.feature_column.indicator_column(\n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(feature, vocab)))\n",
    "\n",
    "# Create NumericColumn for numerical features\n",
    "for feature in NUM_COLUMNS:\n",
    "  feature_cols.append(tf.feature_column.numeric_column(feature, dtype=tf.float32))\n",
    "\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "44913110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>), ('age', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>), ('parch', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>), ('fare', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>), ('class', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('embark_town', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>), ('age', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>), ('parch', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>), ('fare', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>), ('class', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('embark_town', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 03:55:10.388493: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 18ms/step - loss: 0.7251 - binary_accuracy: 0.3716\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.7120 - binary_accuracy: 0.3700\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.7019 - binary_accuracy: 0.3716\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6938 - binary_accuracy: 0.4179\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6871 - binary_accuracy: 0.5742\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6811 - binary_accuracy: 0.6938\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6754 - binary_accuracy: 0.7033\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6696 - binary_accuracy: 0.6635\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6639 - binary_accuracy: 0.6443\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6565 - binary_accuracy: 0.6380\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6495 - binary_accuracy: 0.6284\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6424 - binary_accuracy: 0.6268\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6360 - binary_accuracy: 0.6252\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6300 - binary_accuracy: 0.6252\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6244 - binary_accuracy: 0.6284\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6187 - binary_accuracy: 0.6348\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6133 - binary_accuracy: 0.6523\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6077 - binary_accuracy: 0.6730\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6019 - binary_accuracy: 0.6842\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5964 - binary_accuracy: 0.6906\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5907 - binary_accuracy: 0.6874\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5848 - binary_accuracy: 0.7273\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5787 - binary_accuracy: 0.7448\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5725 - binary_accuracy: 0.7544\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5665 - binary_accuracy: 0.7592\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5605 - binary_accuracy: 0.7608\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5544 - binary_accuracy: 0.7719\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5487 - binary_accuracy: 0.7719\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5430 - binary_accuracy: 0.7863\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5377 - binary_accuracy: 0.7959\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5324 - binary_accuracy: 0.7943\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5273 - binary_accuracy: 0.7959\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5225 - binary_accuracy: 0.7990\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5176 - binary_accuracy: 0.8022\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5133 - binary_accuracy: 0.8006\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5089 - binary_accuracy: 0.8006\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5049 - binary_accuracy: 0.8006\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5011 - binary_accuracy: 0.8022\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4976 - binary_accuracy: 0.8038\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4942 - binary_accuracy: 0.8038\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4913 - binary_accuracy: 0.8022\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4882 - binary_accuracy: 0.8038\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4854 - binary_accuracy: 0.8054\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4830 - binary_accuracy: 0.8054\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4806 - binary_accuracy: 0.8054\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4783 - binary_accuracy: 0.8038\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4764 - binary_accuracy: 0.8070\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4744 - binary_accuracy: 0.8054\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4726 - binary_accuracy: 0.8054\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4707 - binary_accuracy: 0.8038\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4688 - binary_accuracy: 0.8054\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4671 - binary_accuracy: 0.8054\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4655 - binary_accuracy: 0.8054\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4640 - binary_accuracy: 0.8054\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4625 - binary_accuracy: 0.8054\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.4614 - binary_accuracy: 0.8038\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4601 - binary_accuracy: 0.8022\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4589 - binary_accuracy: 0.8022\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4575 - binary_accuracy: 0.8022\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4563 - binary_accuracy: 0.8006\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4554 - binary_accuracy: 0.8022\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4542 - binary_accuracy: 0.8022\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4533 - binary_accuracy: 0.8006\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4525 - binary_accuracy: 0.8022\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4515 - binary_accuracy: 0.8038\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4507 - binary_accuracy: 0.8038\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4500 - binary_accuracy: 0.8006\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.4492 - binary_accuracy: 0.8038\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4484 - binary_accuracy: 0.8022\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.4474 - binary_accuracy: 0.8038\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4467 - binary_accuracy: 0.8022\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4459 - binary_accuracy: 0.8054\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4451 - binary_accuracy: 0.8070\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4445 - binary_accuracy: 0.8070\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4438 - binary_accuracy: 0.8086\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4432 - binary_accuracy: 0.8118\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4425 - binary_accuracy: 0.8150\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4421 - binary_accuracy: 0.8086\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4415 - binary_accuracy: 0.8134\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4408 - binary_accuracy: 0.8118\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4404 - binary_accuracy: 0.8102\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4399 - binary_accuracy: 0.8118\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4394 - binary_accuracy: 0.8166\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4388 - binary_accuracy: 0.8102\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4383 - binary_accuracy: 0.8150\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4381 - binary_accuracy: 0.8150\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4376 - binary_accuracy: 0.8118\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4371 - binary_accuracy: 0.8134\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4365 - binary_accuracy: 0.8134\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4362 - binary_accuracy: 0.8118\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4359 - binary_accuracy: 0.8118\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4354 - binary_accuracy: 0.8150\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4349 - binary_accuracy: 0.8134\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.4346 - binary_accuracy: 0.8134\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4341 - binary_accuracy: 0.8150\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4338 - binary_accuracy: 0.8118\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4333 - binary_accuracy: 0.8134\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.4331 - binary_accuracy: 0.8134\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.4328 - binary_accuracy: 0.8150\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4323 - binary_accuracy: 0.8118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2db789b80>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.DenseFeatures(feature_cols))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.fit(train_dataset, epochs=100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "60687f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('sex', <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>), ('age', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float64>), ('parch', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float64>), ('fare', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>), ('class', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('deck', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('embark_town', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>), ('alone', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 03:55:40.202811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.22459026],\n",
       "       [0.10759155],\n",
       "       [0.8802296 ],\n",
       "       [0.10866767],\n",
       "       [0.12162338],\n",
       "       [0.11828666],\n",
       "       [0.1244107 ],\n",
       "       [0.4401081 ],\n",
       "       [0.10685172],\n",
       "       [0.10630254],\n",
       "       [0.49043557],\n",
       "       [0.18720378],\n",
       "       [0.46757835],\n",
       "       [0.7872259 ],\n",
       "       [0.69836456],\n",
       "       [0.12753133],\n",
       "       [0.21515702],\n",
       "       [0.10934617],\n",
       "       [0.09994785],\n",
       "       [0.10654998],\n",
       "       [0.10706964],\n",
       "       [0.1250674 ],\n",
       "       [0.10791885],\n",
       "       [0.12359685],\n",
       "       [0.9375549 ],\n",
       "       [0.12692913],\n",
       "       [0.6634556 ],\n",
       "       [0.72677803],\n",
       "       [0.813334  ],\n",
       "       [0.29800594],\n",
       "       [0.90366983],\n",
       "       [0.19365498],\n",
       "       [0.10627963],\n",
       "       [0.11155994],\n",
       "       [0.0953436 ],\n",
       "       [0.6663874 ],\n",
       "       [0.10613394],\n",
       "       [0.5345392 ],\n",
       "       [0.70957655],\n",
       "       [0.8120674 ],\n",
       "       [0.84365505],\n",
       "       [0.4201832 ],\n",
       "       [0.14704284],\n",
       "       [0.1098848 ],\n",
       "       [0.8615633 ],\n",
       "       [0.56030136],\n",
       "       [0.21979666],\n",
       "       [0.10763743],\n",
       "       [0.11820266],\n",
       "       [0.89468753],\n",
       "       [0.1944797 ],\n",
       "       [0.18664083],\n",
       "       [0.24003766],\n",
       "       [0.18541823],\n",
       "       [0.1075986 ],\n",
       "       [0.10845035],\n",
       "       [0.10643294],\n",
       "       [0.1539916 ],\n",
       "       [0.36220178],\n",
       "       [0.9291628 ],\n",
       "       [0.46326742],\n",
       "       [0.13527687],\n",
       "       [0.5797918 ],\n",
       "       [0.19243455],\n",
       "       [0.12393462],\n",
       "       [0.6221292 ],\n",
       "       [0.09994785],\n",
       "       [0.12896873],\n",
       "       [0.10724568],\n",
       "       [0.78794694],\n",
       "       [0.17985964],\n",
       "       [0.45659012],\n",
       "       [0.54190195],\n",
       "       [0.09395174],\n",
       "       [0.11002868],\n",
       "       [0.74120253],\n",
       "       [0.6092246 ],\n",
       "       [0.675302  ],\n",
       "       [0.13597092],\n",
       "       [0.20400728],\n",
       "       [0.11619883],\n",
       "       [0.18575887],\n",
       "       [0.46932423],\n",
       "       [0.10929379],\n",
       "       [0.5768636 ],\n",
       "       [0.8289312 ],\n",
       "       [0.12633076],\n",
       "       [0.7992064 ],\n",
       "       [0.10676625],\n",
       "       [0.18658358],\n",
       "       [0.18720378],\n",
       "       [0.91360515],\n",
       "       [0.7267826 ],\n",
       "       [0.2173452 ],\n",
       "       [0.72677803],\n",
       "       [0.10973514],\n",
       "       [0.10799707],\n",
       "       [0.187205  ],\n",
       "       [0.9375337 ],\n",
       "       [0.58761144],\n",
       "       [0.12359685],\n",
       "       [0.16047958],\n",
       "       [0.10642043],\n",
       "       [0.10720696],\n",
       "       [0.88938713],\n",
       "       [0.1272188 ],\n",
       "       [0.10603256],\n",
       "       [0.47080904],\n",
       "       [0.10711118],\n",
       "       [0.10709497],\n",
       "       [0.10889284],\n",
       "       [0.10603256],\n",
       "       [0.69836336],\n",
       "       [0.22340243],\n",
       "       [0.9568881 ],\n",
       "       [0.10812274],\n",
       "       [0.12378888],\n",
       "       [0.10729591],\n",
       "       [0.09235143],\n",
       "       [0.10005955],\n",
       "       [0.39703986],\n",
       "       [0.2123829 ],\n",
       "       [0.42108756],\n",
       "       [0.8121831 ],\n",
       "       [0.28684688],\n",
       "       [0.8111635 ],\n",
       "       [0.09932762],\n",
       "       [0.94746286],\n",
       "       [0.85440725],\n",
       "       [0.1075986 ],\n",
       "       [0.11206912],\n",
       "       [0.12378888],\n",
       "       [0.39071447],\n",
       "       [0.11061265],\n",
       "       [0.1918305 ],\n",
       "       [0.72677803],\n",
       "       [0.12298714],\n",
       "       [0.498094  ],\n",
       "       [0.46202153],\n",
       "       [0.5986364 ],\n",
       "       [0.5105105 ],\n",
       "       [0.8110172 ],\n",
       "       [0.10864916],\n",
       "       [0.6713394 ],\n",
       "       [0.52702093],\n",
       "       [0.094933  ],\n",
       "       [0.14286397],\n",
       "       [0.10810124],\n",
       "       [0.81848794],\n",
       "       [0.94639224],\n",
       "       [0.10821917],\n",
       "       [0.10956859],\n",
       "       [0.10439373],\n",
       "       [0.1076254 ],\n",
       "       [0.4619544 ],\n",
       "       [0.43991393],\n",
       "       [0.96291465],\n",
       "       [0.10665125],\n",
       "       [0.2989633 ],\n",
       "       [0.80387664],\n",
       "       [0.10983063],\n",
       "       [0.3026052 ],\n",
       "       [0.8324939 ],\n",
       "       [0.1067503 ],\n",
       "       [0.10760415],\n",
       "       [0.82092655],\n",
       "       [0.48573306],\n",
       "       [0.6528477 ],\n",
       "       [0.80775434],\n",
       "       [0.12143425],\n",
       "       [0.10597973],\n",
       "       [0.10694847],\n",
       "       [0.1075986 ],\n",
       "       [0.19512814],\n",
       "       [0.12426449],\n",
       "       [0.81901413],\n",
       "       [0.10786039],\n",
       "       [0.2921525 ],\n",
       "       [0.2235226 ],\n",
       "       [0.9115124 ],\n",
       "       [0.1063035 ],\n",
       "       [0.83478284],\n",
       "       [0.12284236],\n",
       "       [0.41821036],\n",
       "       [0.13782358],\n",
       "       [0.7149597 ],\n",
       "       [0.8246037 ],\n",
       "       [0.952148  ],\n",
       "       [0.12541461],\n",
       "       [0.17358232],\n",
       "       [0.10762823],\n",
       "       [0.9254418 ],\n",
       "       [0.10444267],\n",
       "       [0.1075986 ],\n",
       "       [0.20097546],\n",
       "       [0.79582417],\n",
       "       [0.11003961],\n",
       "       [0.8992919 ],\n",
       "       [0.39703986],\n",
       "       [0.5270128 ],\n",
       "       [0.90651745],\n",
       "       [0.1346478 ],\n",
       "       [0.14021485],\n",
       "       [0.12284236],\n",
       "       [0.10759155],\n",
       "       [0.8806622 ],\n",
       "       [0.8585698 ],\n",
       "       [0.28921026],\n",
       "       [0.8356797 ],\n",
       "       [0.18720558],\n",
       "       [0.10649656],\n",
       "       [0.377275  ],\n",
       "       [0.09994785],\n",
       "       [0.10752502],\n",
       "       [0.5113133 ],\n",
       "       [0.90986407],\n",
       "       [0.12359685],\n",
       "       [0.8602208 ],\n",
       "       [0.80590695],\n",
       "       [0.32724208],\n",
       "       [0.1075986 ],\n",
       "       [0.09545751],\n",
       "       [0.13269873],\n",
       "       [0.09578825],\n",
       "       [0.95962805],\n",
       "       [0.1075986 ],\n",
       "       [0.22619843],\n",
       "       [0.10620367],\n",
       "       [0.45339823],\n",
       "       [0.8534013 ],\n",
       "       [0.93154216],\n",
       "       [0.12359685],\n",
       "       [0.7161173 ],\n",
       "       [0.64303493],\n",
       "       [0.12695135],\n",
       "       [0.10812467],\n",
       "       [0.10855298],\n",
       "       [0.18035905],\n",
       "       [0.09435859],\n",
       "       [0.88980424],\n",
       "       [0.18092507],\n",
       "       [0.10733776],\n",
       "       [0.8627114 ],\n",
       "       [0.10733739],\n",
       "       [0.72674245],\n",
       "       [0.19571051],\n",
       "       [0.11485691],\n",
       "       [0.12847404],\n",
       "       [0.36397964],\n",
       "       [0.78794694],\n",
       "       [0.40046954],\n",
       "       [0.13632336],\n",
       "       [0.28173232],\n",
       "       [0.90075403],\n",
       "       [0.5345392 ],\n",
       "       [0.61709976],\n",
       "       [0.10917778],\n",
       "       [0.10642745],\n",
       "       [0.94291824],\n",
       "       [0.76466364],\n",
       "       [0.10667969],\n",
       "       [0.10669128],\n",
       "       [0.11005663],\n",
       "       [0.10761448],\n",
       "       [0.28173995],\n",
       "       [0.1275312 ],\n",
       "       [0.10759155],\n",
       "       [0.3137996 ],\n",
       "       [0.19063182],\n",
       "       [0.15843755],\n",
       "       [0.10756867],\n",
       "       [0.1075986 ],\n",
       "       [0.10648405],\n",
       "       [0.11743226],\n",
       "       [0.10665183],\n",
       "       [0.6311211 ],\n",
       "       [0.72674245],\n",
       "       [0.9046194 ],\n",
       "       [0.10641551],\n",
       "       [0.10760051],\n",
       "       [0.11291002],\n",
       "       [0.12488836],\n",
       "       [0.1246537 ],\n",
       "       [0.36538678],\n",
       "       [0.9110081 ],\n",
       "       [0.9367572 ],\n",
       "       [0.1347453 ],\n",
       "       [0.12847404],\n",
       "       [0.9250853 ],\n",
       "       [0.18720528],\n",
       "       [0.10759155],\n",
       "       [0.7972432 ],\n",
       "       [0.6281755 ],\n",
       "       [0.10812142],\n",
       "       [0.7599186 ],\n",
       "       [0.6768398 ],\n",
       "       [0.7522359 ],\n",
       "       [0.10538859],\n",
       "       [0.10613394],\n",
       "       [0.1085102 ],\n",
       "       [0.18720378],\n",
       "       [0.10759155],\n",
       "       [0.7063373 ],\n",
       "       [0.10759155],\n",
       "       [0.855194  ],\n",
       "       [0.14298962],\n",
       "       [0.60472745],\n",
       "       [0.92180014],\n",
       "       [0.8131943 ],\n",
       "       [0.1075986 ],\n",
       "       [0.7324209 ],\n",
       "       [0.10928192],\n",
       "       [0.18715228],\n",
       "       [0.10825975],\n",
       "       [0.5739419 ],\n",
       "       [0.10646832],\n",
       "       [0.12204588],\n",
       "       [0.864534  ],\n",
       "       [0.89443785],\n",
       "       [0.47794724],\n",
       "       [0.31973568],\n",
       "       [0.2762527 ],\n",
       "       [0.18177676],\n",
       "       [0.18726194],\n",
       "       [0.9522531 ],\n",
       "       [0.16576566],\n",
       "       [0.09628627],\n",
       "       [0.3756288 ],\n",
       "       [0.10904406],\n",
       "       [0.8211365 ],\n",
       "       [0.10694658],\n",
       "       [0.5261171 ],\n",
       "       [0.09994785],\n",
       "       [0.108293  ],\n",
       "       [0.1269512 ],\n",
       "       [0.4657052 ],\n",
       "       [0.1065589 ],\n",
       "       [0.2128377 ],\n",
       "       [0.5119618 ],\n",
       "       [0.82661074],\n",
       "       [0.26602936],\n",
       "       [0.91149926],\n",
       "       [0.21650998],\n",
       "       [0.8692596 ],\n",
       "       [0.10758868],\n",
       "       [0.18720378],\n",
       "       [0.93395156],\n",
       "       [0.5291424 ],\n",
       "       [0.70633245],\n",
       "       [0.101379  ],\n",
       "       [0.52360964],\n",
       "       [0.15146337],\n",
       "       [0.19686772],\n",
       "       [0.5431419 ],\n",
       "       [0.12174187],\n",
       "       [0.10765652],\n",
       "       [0.6316177 ],\n",
       "       [0.12096797],\n",
       "       [0.8191576 ],\n",
       "       [0.18720378],\n",
       "       [0.10760415],\n",
       "       [0.22509785],\n",
       "       [0.1068166 ],\n",
       "       [0.08665898],\n",
       "       [0.68965167],\n",
       "       [0.8440449 ],\n",
       "       [0.11340087],\n",
       "       [0.10590325],\n",
       "       [0.12522472],\n",
       "       [0.48436126],\n",
       "       [0.12359685],\n",
       "       [0.18803401],\n",
       "       [0.4536159 ],\n",
       "       [0.8491099 ],\n",
       "       [0.34508696],\n",
       "       [0.7958275 ],\n",
       "       [0.2386196 ],\n",
       "       [0.10746792],\n",
       "       [0.16837929],\n",
       "       [0.46281627],\n",
       "       [0.11013858],\n",
       "       [0.10773499],\n",
       "       [0.5512705 ],\n",
       "       [0.8404048 ],\n",
       "       [0.10895243],\n",
       "       [0.10733739],\n",
       "       [0.7751252 ],\n",
       "       [0.10756344],\n",
       "       [0.5392942 ],\n",
       "       [0.539244  ],\n",
       "       [0.86746013],\n",
       "       [0.78794694],\n",
       "       [0.10759155],\n",
       "       [0.10538859],\n",
       "       [0.9369088 ],\n",
       "       [0.57667804],\n",
       "       [0.11175039],\n",
       "       [0.7267677 ],\n",
       "       [0.5571343 ],\n",
       "       [0.9431328 ],\n",
       "       [0.17107685],\n",
       "       [0.8982953 ],\n",
       "       [0.39069954],\n",
       "       [0.10760319],\n",
       "       [0.1066854 ],\n",
       "       [0.76039237],\n",
       "       [0.1051321 ],\n",
       "       [0.1065955 ],\n",
       "       [0.1075986 ],\n",
       "       [0.8632371 ],\n",
       "       [0.5181035 ],\n",
       "       [0.12688461],\n",
       "       [0.2082696 ],\n",
       "       [0.36538678],\n",
       "       [0.12695135],\n",
       "       [0.5509155 ],\n",
       "       [0.9193505 ],\n",
       "       [0.10939431],\n",
       "       [0.85434127],\n",
       "       [0.13107108],\n",
       "       [0.3317615 ],\n",
       "       [0.10444888],\n",
       "       [0.7607375 ],\n",
       "       [0.10759155],\n",
       "       [0.92822653],\n",
       "       [0.78697544],\n",
       "       [0.15626709],\n",
       "       [0.10985997],\n",
       "       [0.61657715],\n",
       "       [0.8598382 ],\n",
       "       [0.4692809 ],\n",
       "       [0.29825348],\n",
       "       [0.12050323],\n",
       "       [0.93420255],\n",
       "       [0.10538859],\n",
       "       [0.187198  ],\n",
       "       [0.82333946],\n",
       "       [0.8507866 ],\n",
       "       [0.82011974],\n",
       "       [0.61075133],\n",
       "       [0.72677803],\n",
       "       [0.10837856],\n",
       "       [0.11079092],\n",
       "       [0.10666224],\n",
       "       [0.11063594],\n",
       "       [0.1102438 ],\n",
       "       [0.10983457],\n",
       "       [0.08840092],\n",
       "       [0.894779  ],\n",
       "       [0.12599255],\n",
       "       [0.14611694],\n",
       "       [0.11074656],\n",
       "       [0.4804364 ],\n",
       "       [0.8471391 ],\n",
       "       [0.57888865],\n",
       "       [0.8006925 ],\n",
       "       [0.1075986 ],\n",
       "       [0.10684603],\n",
       "       [0.10752502],\n",
       "       [0.10858399],\n",
       "       [0.54456764],\n",
       "       [0.12050323],\n",
       "       [0.15655568],\n",
       "       [0.88875407],\n",
       "       [0.89062756],\n",
       "       [0.83319175],\n",
       "       [0.5394067 ],\n",
       "       [0.10765576],\n",
       "       [0.77176195],\n",
       "       [0.46191737],\n",
       "       [0.37960422],\n",
       "       [0.1075986 ],\n",
       "       [0.836306  ],\n",
       "       [0.8531781 ],\n",
       "       [0.65041685],\n",
       "       [0.12692913],\n",
       "       [0.72677803],\n",
       "       [0.5826871 ],\n",
       "       [0.12734789],\n",
       "       [0.7856045 ],\n",
       "       [0.8388551 ],\n",
       "       [0.10249615],\n",
       "       [0.9426579 ],\n",
       "       [0.1269512 ],\n",
       "       [0.9498111 ],\n",
       "       [0.10684603],\n",
       "       [0.72674245],\n",
       "       [0.9185739 ],\n",
       "       [0.10734291],\n",
       "       [0.50209993],\n",
       "       [0.68965167],\n",
       "       [0.127096  ],\n",
       "       [0.5351823 ],\n",
       "       [0.95108813],\n",
       "       [0.36792302],\n",
       "       [0.93640405],\n",
       "       [0.94481754],\n",
       "       [0.10539368],\n",
       "       [0.18726861],\n",
       "       [0.12064566],\n",
       "       [0.9129184 ],\n",
       "       [0.10188215],\n",
       "       [0.4423608 ],\n",
       "       [0.11124033],\n",
       "       [0.88179266],\n",
       "       [0.10759155],\n",
       "       [0.5451817 ],\n",
       "       [0.10733033],\n",
       "       [0.7113269 ],\n",
       "       [0.1313468 ],\n",
       "       [0.12695135],\n",
       "       [0.81353325],\n",
       "       [0.11880023],\n",
       "       [0.10678685],\n",
       "       [0.5372341 ],\n",
       "       [0.1332631 ],\n",
       "       [0.10945906],\n",
       "       [0.93351537],\n",
       "       [0.5985018 ],\n",
       "       [0.31947955],\n",
       "       [0.11880023],\n",
       "       [0.30969328],\n",
       "       [0.10682114],\n",
       "       [0.12143425],\n",
       "       [0.1500509 ],\n",
       "       [0.10538859],\n",
       "       [0.39678404],\n",
       "       [0.36136553],\n",
       "       [0.18629357],\n",
       "       [0.1549534 ],\n",
       "       [0.11078787],\n",
       "       [0.5345392 ],\n",
       "       [0.116572  ],\n",
       "       [0.09999482],\n",
       "       [0.32998723],\n",
       "       [0.30185637],\n",
       "       [0.79122734],\n",
       "       [0.12526307],\n",
       "       [0.19512814],\n",
       "       [0.10762823],\n",
       "       [0.12887104],\n",
       "       [0.16641644],\n",
       "       [0.61709976],\n",
       "       [0.10818018],\n",
       "       [0.89197296],\n",
       "       [0.52901995],\n",
       "       [0.35246068],\n",
       "       [0.18720378],\n",
       "       [0.8494603 ],\n",
       "       [0.72677803],\n",
       "       [0.09838921],\n",
       "       [0.10759155],\n",
       "       [0.10630463],\n",
       "       [0.96193314],\n",
       "       [0.18720378],\n",
       "       [0.16964006],\n",
       "       [0.1075986 ],\n",
       "       [0.10642745],\n",
       "       [0.13782358],\n",
       "       [0.10092376],\n",
       "       [0.84824324],\n",
       "       [0.7724867 ],\n",
       "       [0.09452643],\n",
       "       [0.54545105],\n",
       "       [0.9182157 ],\n",
       "       [0.1075986 ],\n",
       "       [0.57569087],\n",
       "       [0.40349543],\n",
       "       [0.70753175],\n",
       "       [0.13886958],\n",
       "       [0.09665922],\n",
       "       [0.09414479],\n",
       "       [0.12666608],\n",
       "       [0.11068281],\n",
       "       [0.30227876],\n",
       "       [0.7872087 ],\n",
       "       [0.2344277 ],\n",
       "       [0.5141077 ],\n",
       "       [0.1059669 ],\n",
       "       [0.10724568],\n",
       "       [0.9466319 ],\n",
       "       [0.80590695],\n",
       "       [0.6414129 ],\n",
       "       [0.8429304 ],\n",
       "       [0.15655568],\n",
       "       [0.69436   ],\n",
       "       [0.80177426],\n",
       "       [0.25724626],\n",
       "       [0.9198281 ],\n",
       "       [0.10970731],\n",
       "       [0.10632408],\n",
       "       [0.10812142],\n",
       "       [0.10855646],\n",
       "       [0.26208314],\n",
       "       [0.85865146],\n",
       "       [0.10743277],\n",
       "       [0.10707668],\n",
       "       [0.8616483 ],\n",
       "       [0.15617044],\n",
       "       [0.6140214 ],\n",
       "       [0.10400914],\n",
       "       [0.11040375],\n",
       "       [0.40806323],\n",
       "       [0.10669222],\n",
       "       [0.37840432],\n",
       "       [0.25976446],\n",
       "       [0.16392428],\n",
       "       [0.9372829 ],\n",
       "       [0.53017515],\n",
       "       [0.08097766],\n",
       "       [0.10837856],\n",
       "       [0.3181323 ],\n",
       "       [0.469701  ],\n",
       "       [0.1269512 ],\n",
       "       [0.10006517],\n",
       "       [0.80365855],\n",
       "       [0.3108544 ],\n",
       "       [0.15862001],\n",
       "       [0.12570071],\n",
       "       [0.21503866],\n",
       "       [0.88529104],\n",
       "       [0.22226551],\n",
       "       [0.8790506 ],\n",
       "       [0.10680953],\n",
       "       [0.4655209 ],\n",
       "       [0.10901513],\n",
       "       [0.09988747]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e804fb-11be-472e-ab04-d041fa63260b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_everyone",
   "language": "python",
   "name": "ml_for_everyone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
