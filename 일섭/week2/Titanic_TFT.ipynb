{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265b1c7d-953a-4c68-af45-fd5ed41cc0ba",
   "metadata": {},
   "source": [
    "# TFT with Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf3ea5-0761-40da-997e-44ac92ea6e11",
   "metadata": {},
   "source": [
    "## 1. import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637fb98a-d627-425e-bb01-4cabe4ef8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import apache_beam as beam\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "\n",
    "from tfx_bsl.public import tfxio\n",
    "from tfx_bsl.coders.example_coder import RecordBatchToExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bcd6c9-572d-4328-b1b8-e28e10114e3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890464b9-781d-4f81-a427-277f0deb5882",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"D:\\\\Study\\\\ML\\\\So1s-Study\\\\일섭\\\\week2\\\\titanic\\\\data\\\\train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"D:\\\\Study\\\\ML\\\\So1s-Study\\\\일섭\\\\week2\\\\titanic\\\\data\\\\eval.csv\", TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75aec359-2c37-4c78-a99e-67b9f60eefbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = os.path.join('D:\\\\Study\\\\ML\\\\So1s-Study\\\\일섭\\\\week2', 'titanic')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n",
    "TRAIN_DATA = os.path.join(DATA_DIR, 'train_num.csv')\n",
    "TEST_DATA = os.path.join(DATA_DIR, 'eval_num.csv')\n",
    "\n",
    "os.path.isdir(BASE_DIR), os.path.isdir(DATA_DIR), os.path.isdir(OUTPUT_DIR), os.path.isfile(TRAIN_DATA),  os.path.isfile(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c4a9ca-f2bb-40be-8477-571b5003d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'n_siblings_spouses', 'parch', 'fare']\n",
    "CATEGORICAL_COLUMNS = ['class', 'deck', 'sex', 'embark_town', 'alone']\n",
    "LABEL_KEY = 'survived'\n",
    "\n",
    "# 처음에 컬럼이름을 문자열로 했는데 자꾸 컬럼이름을 float 형태로 바꾸려는 시도를 해서 오류가 나서 바꿈.\n",
    "SELECTED_COLUMNS = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "NUMERIC_COLUMNS = ['3', '4', '5', '6']\n",
    "CATEGORICAL_COLUMNS = ['2', '7', '8', '9', '10']\n",
    "LABEL_KEY = '1'\n",
    "\n",
    "TRANSFORMED_TRAIN_DATA_FILEBASE='train_transformed'\n",
    "TRANSFORMED_TEST_DATA_FILEBASE='test_transformed'\n",
    "\n",
    "NUM_OOV_BUCKETS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46448a11-e1e1-42ea-aeb6-63c60bf9f85d",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "617bb5c5-b12a-411e-bf90-b313aaf76ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(inputs):\n",
    "    outputs = inputs.copy()\n",
    "    \n",
    "    #NUMERIC Data\n",
    "    for key in NUMERIC_COLUMNS:\n",
    "        outputs[key] = tft.scale_to_0_1(inputs[key])\n",
    "    \n",
    "    # CATEGORI Data\n",
    "    for key in CATEGORICAL_COLUMNS:\n",
    "        outputs[key] = tft.compute_and_apply_vocabulary(\n",
    "            tf.strings.strip(inputs[key]),\n",
    "            num_oov_buckets=NUM_OOV_BUCKETS,\n",
    "            vocab_filename=key)\n",
    "        \n",
    "    # Label\n",
    "    table_keys = ['0', '1']\n",
    "    with tf.init_scope():\n",
    "        initializer = tf.lookup.KeyValueTensorInitializer(\n",
    "            keys=table_keys,\n",
    "            values=tf.cast(tf.range(len(table_keys)), tf.int64),\n",
    "            key_dtype=tf.string,\n",
    "            value_dtype=tf.int64)\n",
    "        table = tf.lookup.StaticHashTable(initializer, default_value=-1)\n",
    "    \n",
    "    label_str = inputs[LABEL_KEY]\n",
    "    label_str = tf.strings.strip(label_str)\n",
    "    data_labels = table.lookup(label_str)\n",
    "    transformed_label = tf.one_hot(\n",
    "        indices=data_labels, depth=2, on_value=1.0, off_value=0.0)\n",
    "    outputs[LABEL_KEY] = tf.reshape(transformed_label, [-1, len(table_keys)])\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5bf3e2-74cb-4048-8ce1-03a9ce667d5d",
   "metadata": {},
   "source": [
    "## 4. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "467f9218-3e7f-4dfa-86cb-ed0e4cd76391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " '7': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " '8': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " '9': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " '10': FixedLenFeature(shape=[], dtype=tf.string, default_value=None),\n",
       " '3': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '4': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '5': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '6': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '1': FixedLenFeature(shape=[], dtype=tf.string, default_value=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data_feature_meta = dict(\n",
    "    [(key, tf.io.FixedLenFeature([], tf.string)) for key in CATEGORICAL_COLUMNS] +\n",
    "    [(key, tf.io.FixedLenFeature([], tf.float32)) for key in NUMERIC_COLUMNS] + \n",
    "    [(LABEL_KEY, tf.io.FixedLenFeature([], tf.string))]\n",
    ")\n",
    "\n",
    "schema = tft.tf_metadata.dataset_metadata.DatasetMetadata(\n",
    "    tft.tf_metadata.schema_utils.schema_from_feature_spec(titanic_data_feature_meta)).schema\n",
    "\n",
    "titanic_data_feature_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e6b26-59cf-47bd-b442-4ad0ddcbde60",
   "metadata": {},
   "source": [
    "## 5. Transform Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b62c3d2-861d-46f2-87f3-b30121fdce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_file, test_data_file, working_dir):\n",
    "    with beam.Pipeline() as pipeline:\n",
    "        with tft_beam.Context(temp_dir=os.path.join(working_dir)):\n",
    "\n",
    "            # dataset load\n",
    "            train_csv_tfxio = tfxio.CsvTFXIO(\n",
    "                file_pattern=train_data_file,\n",
    "                telemetry_descriptors=[],\n",
    "                column_names=SELECTED_COLUMNS,\n",
    "                schema=schema)\n",
    "\n",
    "            raw_data = (\n",
    "                pipeline |\n",
    "                'ReadTrainCsv' >> train_csv_tfxio.BeamSource())\n",
    "            \n",
    "            raw_dataset = (raw_data, train_csv_tfxio.TensorAdapterConfig())\n",
    "\n",
    "            #transform\n",
    "            transformed_dataset, transform_fn = (\n",
    "                raw_dataset | tft_beam.AnalyzeAndTransformDataset(\n",
    "                    preprocessing_fn, output_record_batches=True))\n",
    "\n",
    "            transformed_data, _ = transformed_dataset\n",
    "\n",
    "            _ = (\n",
    "                transformed_data\n",
    "                | 'EncodeTrainData' >>\n",
    "                beam.FlatMapTuple(lambda batch, _: RecordBatchToExamples(batch))\n",
    "                | 'WriteTrainData' >> beam.io.WriteToTFRecord(\n",
    "                    os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE)))\n",
    "            \n",
    "            test_csv_tfxio = tfxio.CsvTFXIO(\n",
    "                file_pattern=test_data_file,\n",
    "                skip_header_lines=1,\n",
    "                telemetry_descriptors=[],\n",
    "                column_names=SELECTED_COLUMNS,\n",
    "                schema=schema)\n",
    "            raw_test_data = (\n",
    "                pipeline |\n",
    "                'ReadTestCsv' >> test_csv_tfxio.BeamSource())\n",
    "            \n",
    "            raw_test_dataset = (raw_test_data, test_csv_tfxio.TensorAdapterConfig())\n",
    "\n",
    "            #transform\n",
    "            transformed_test_dataset = (\n",
    "                (raw_test_dataset, transform_fn)\n",
    "                | tft_beam.TransformDataset(output_record_batches=True))\n",
    "\n",
    "            transformed_test_data, _ = transformed_test_dataset\n",
    "\n",
    "            _ = (\n",
    "                transformed_test_data\n",
    "                | 'EncodeTestData' >>\n",
    "                beam.FlatMapTuple(lambda batch, _: RecordBatchToExamples(batch))\n",
    "                | 'WriteTestData' >> beam.io.WriteToTFRecord(\n",
    "                    os.path.join(working_dir, TRANSFORMED_TEST_DATA_FILEBASE)))\n",
    "        \n",
    "        \n",
    "            # 이부분에서 ValueError : string to float b'age' 에러가 남.\n",
    "            _ = (transform_fn | 'WriteTransformFn' >> tft_beam.WriteTransformFn(working_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a692d2d6-5285-4cb1-a941-11b72c1c48a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shini\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_transform\\tf_utils.py:326: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shini\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_transform\\tf_utils.py:326: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\So1s-Study\\일섭\\week2\\titanic\\output\\tftransform_tmp\\bf8a774ba0d6422a89b9371be44dc0cf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\So1s-Study\\일섭\\week2\\titanic\\output\\tftransform_tmp\\bf8a774ba0d6422a89b9371be44dc0cf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\So1s-Study\\일섭\\week2\\titanic\\output\\tftransform_tmp\\cbe6258fe448477fa0c1ac477e4e9529\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Study\\ML\\So1s-Study\\일섭\\week2\\titanic\\output\\tftransform_tmp\\cbe6258fe448477fa0c1ac477e4e9529\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    }
   ],
   "source": [
    "transform_data(TRAIN_DATA,TEST_DATA,OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f11ad8-a5e2-4147-95b4-5f68c135954a",
   "metadata": {},
   "source": [
    "# Dataset Read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda0386-32ad-42b8-a90e-cd8dd59813a0",
   "metadata": {},
   "source": [
    "## 1. Read Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d0a3065-d9aa-4e38-9552-2790f211a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transform_output = tft.TFTransformOutput(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe5b0df1-8843-4865-8d22-d6342470e747",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': FixedLenFeature(shape=[2], dtype=tf.float32, default_value=None),\n",
       " '10': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " '2': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " '3': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '4': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '5': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '6': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None),\n",
       " '7': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " '8': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None),\n",
       " '9': FixedLenFeature(shape=[], dtype=tf.int64, default_value=None)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transform_output.transformed_feature_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe629ae1-2a05-4f4f-8b71-4c5fd0ce87f2",
   "metadata": {},
   "source": [
    "## 2. Read Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcd7379d-636a-4044-b3e7-27e8034dae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_training_input_fn(tf_transform_output, train_file_pattern, batch_size):\n",
    "    def input_fn():\n",
    "        return tf.data.experimental.make_batched_features_dataset(\n",
    "            file_pattern=train_file_pattern,\n",
    "            batch_size=batch_size,\n",
    "            features=tf_transform_output.transformed_feature_spec(),\n",
    "            reader=tf.data.TFRecordDataset,\n",
    "            label_key=LABEL_KEY,\n",
    "            shuffle=True)\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7698cb9d-adaa-4547-848f-52291c8ebfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_pattern = pathlib.Path(OUTPUT_DIR)/f'{TRANSFORMED_TRAIN_DATA_FILEBASE}*'\n",
    "\n",
    "input_fn = _make_training_input_fn(\n",
    "    tf_transform_output=tf_transform_output,\n",
    "    train_file_pattern = str(train_file_pattern),\n",
    "    batch_size = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d701618-7686-4f81-8bd5-7286d3bf24b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230284</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343849</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.501577</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747634</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146878</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520505</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343849</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305994</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343849</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  2         3      4    5         6  7  8  9\n",
       "0   0  0  0.230284  0.000  0.0  0.013175  0  0  2\n",
       "1   0  0  0.444795  0.000  0.0  0.000000  0  0  0\n",
       "2   0  0  0.343849  0.000  0.0  0.015713  0  0  0\n",
       "3   0  0  0.520505  0.000  0.0  0.014737  0  0  0\n",
       "4   1  0  0.501577  0.000  0.4  0.028302  0  0  0\n",
       "5   1  1  0.747634  0.125  0.0  0.146878  1  4  1\n",
       "6   0  1  0.520505  0.000  0.0  0.444099  1  0  1\n",
       "7   0  0  0.343849  0.000  0.0  0.027058  2  0  1\n",
       "8   1  0  0.305994  0.125  0.0  0.015176  0  0  0\n",
       "9   0  0  0.343849  0.000  0.0  0.016510  0  0  2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for example, label in input_fn().take(1):\n",
    "    # print(pd.DataFrame(example)['10'].values)\n",
    "    break\n",
    "\n",
    "pd.DataFrame(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e037f9-5691-42bf-87b9-731091e1c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deafd25e-6996-4b39-9e77-989e2ef801f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keras_model(working_dir):\n",
    "    inputs = build_keras_inputs(working_dir)\n",
    "\n",
    "    encoded_inputs = encode_inputs(inputs)\n",
    "\n",
    "    stacked_inputs = tf.concat(tf.nest.flatten(encoded_inputs), axis=1)\n",
    "    output = tf.keras.layers.Dense(100, activation='relu')(stacked_inputs)\n",
    "    output = tf.keras.layers.Dense(50, activation='relu')(output)\n",
    "    output = tf.keras.layers.Dense(2)(output)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb7d4386-183c-4c15-9de9-b4f35574fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keras_inputs(working_dir):\n",
    "    tf_transform_output = tft.TFTransformOutput(working_dir)\n",
    "\n",
    "    feature_spec = tf_transform_output.transformed_feature_spec().copy()\n",
    "    feature_spec.pop(LABEL_KEY)\n",
    "\n",
    "    # Build the `keras.Input` objects.\n",
    "    inputs = {}\n",
    "    for key, spec in feature_spec.items():\n",
    "        if isinstance(spec, tf.io.VarLenFeature):\n",
    "            inputs[key] = tf.keras.layers.Input(\n",
    "                shape=[None], name=key, dtype=spec.dtype, sparse=True)\n",
    "        elif isinstance(spec, tf.io.FixedLenFeature):\n",
    "            inputs[key] = tf.keras.layers.Input(\n",
    "                shape=spec.shape, name=key, dtype=spec.dtype)\n",
    "        else:\n",
    "            raise ValueError('Spec type is not supported: ', key, spec)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e17e5a2-f69b-4754-9de7-a35d5b31f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_inputs(inputs):\n",
    "    encoded_inputs = {}\n",
    "    for key in inputs:\n",
    "        feature = tf.expand_dims(inputs[key], -1)\n",
    "        if key in CATEGORICAL_COLUMNS:\n",
    "            num_buckets = tf_transform_output.num_buckets_for_transformed_feature(key)\n",
    "            encoding_layer = (\n",
    "                tf.keras.layers.CategoryEncoding(\n",
    "                    num_tokens=num_buckets, output_mode='binary', sparse=False))\n",
    "            encoded_inputs[key] = encoding_layer(feature)\n",
    "        else:\n",
    "            encoded_inputs[key] = feature\n",
    "  \n",
    "    return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1822b1-c0e2-4cfb-8d09-6a61d89c1659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "model = build_keras_model(OUTPUT_DIR)\n",
    "\n",
    "tf.keras.utils.plot_model(model,rankdir='LR', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c725512-d747-4857-ae96-90ff5bab0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(working_dir, filebase):\n",
    "    tf_transform_output = tft.TFTransformOutput(working_dir)\n",
    "\n",
    "    data_path_pattern = os.path.join(\n",
    "        working_dir,\n",
    "        filebase + '*')\n",
    "\n",
    "    input_fn = _make_training_input_fn(\n",
    "        tf_transform_output,\n",
    "        data_path_pattern,\n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    dataset = input_fn()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "160e7699-d3c7-4d07-892a-860aa05fd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, working_dir):\n",
    "    train_dataset = get_dataset(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE)\n",
    "    validation_dataset = get_dataset(working_dir, TRANSFORMED_TEST_DATA_FILEBASE)\n",
    "\n",
    "    model = build_keras_model(working_dir)\n",
    "\n",
    "    history = train_model(model, train_dataset, validation_dataset)\n",
    "\n",
    "    metric_values = model.evaluate(validation_dataset,\n",
    "                                 steps=EVALUATION_STEPS,\n",
    "                                 return_dict=True)\n",
    "    return model, history, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa68fab9-9181-4e82-8d6c-130640c65428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, validation_dataset):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_dataset, validation_data=validation_dataset,\n",
    "        epochs=TRAIN_NUM_EPOCHS,\n",
    "        steps_per_epoch=STEPS_PER_TRAIN_EPOCH,\n",
    "        validation_steps=EVALUATION_STEPS)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e6f22-b006-403a-99b0-e69e1212a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_train = pd.read_csv(TRAIN_DATA, header=None, names=SELECTED_COLUMNS)\n",
    "pandas_test = pd.read_csv(TEST_DATA, header=1, names=SELECTED_COLUMNS)\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "  '' if isinstance(v, str) else 0.0\n",
    "  for v in  dict(pandas_train.loc[1]).values()]\n",
    "\n",
    "EPOCH_SPLITS = 10\n",
    "TRAIN_NUM_EPOCHS = 2*EPOCH_SPLITS\n",
    "NUM_TRAIN_INSTANCES = len(pandas_train)\n",
    "NUM_TEST_INSTANCES = len(pandas_test)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "STEPS_PER_TRAIN_EPOCH = tf.math.ceil(NUM_TRAIN_INSTANCES/BATCH_SIZE/EPOCH_SPLITS)\n",
    "EVALUATION_STEPS = tf.math.ceil(NUM_TEST_INSTANCES/BATCH_SIZE)\n",
    "\n",
    "# Names of temp files\n",
    "TRANSFORMED_TRAIN_DATA_FILEBASE = 'train_transformed'\n",
    "TRANSFORMED_TEST_DATA_FILEBASE = 'test_transformed'\n",
    "EXPORTED_MODEL_DIR = 'exported_model_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d814f-ab16-486f-8125-21bc28aba2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7419 - accuracy: 0.3359 - val_loss: 0.7248 - val_accuracy: 0.3229\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.7297 - accuracy: 0.2656 - val_loss: 0.7095 - val_accuracy: 0.3776\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.7028 - accuracy: 0.4375 - val_loss: 0.6907 - val_accuracy: 0.5651\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6913 - accuracy: 0.5781 - val_loss: 0.6775 - val_accuracy: 0.6094\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6591 - accuracy: 0.6875 - val_loss: 0.6626 - val_accuracy: 0.6328\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6516 - accuracy: 0.6406 - val_loss: 0.6493 - val_accuracy: 0.6432\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6377 - accuracy: 0.6797 - val_loss: 0.6379 - val_accuracy: 0.6432\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.6237 - accuracy: 0.6719 - val_loss: 0.6308 - val_accuracy: 0.6354\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6398 - accuracy: 0.6406 - val_loss: 0.6195 - val_accuracy: 0.6458\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6151 - accuracy: 0.6406 - val_loss: 0.6063 - val_accuracy: 0.6693\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5979 - accuracy: 0.6875 - val_loss: 0.6091 - val_accuracy: 0.6484\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.6161 - accuracy: 0.6406 - val_loss: 0.5944 - val_accuracy: 0.6875\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.5837 - accuracy: 0.7188 - val_loss: 0.5862 - val_accuracy: 0.6901\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6049 - accuracy: 0.6328 - val_loss: 0.5928 - val_accuracy: 0.6849\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5841 - accuracy: 0.6797 - val_loss: 0.5871 - val_accuracy: 0.6953\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.6177 - accuracy: 0.6016 - val_loss: 0.5724 - val_accuracy: 0.7057\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5451 - accuracy: 0.7344 - val_loss: 0.5696 - val_accuracy: 0.7109\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5352 - accuracy: 0.7656 - val_loss: 0.5560 - val_accuracy: 0.7266\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4940 - accuracy: 0.8125 - val_loss: 0.5515 - val_accuracy: 0.7370\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5761 - accuracy: 0.7188 - val_loss: 0.5472 - val_accuracy: 0.7422\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5475 - accuracy: 0.7474\n"
     ]
    }
   ],
   "source": [
    "model, history, metric_values = train_and_evaluate(model, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bbc54-38fa-41bf-a982-ac489dbe1f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Eval')\n",
    "plt.ylim(0,max(plt.ylim()))\n",
    "plt.legend()\n",
    "plt.title('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fef7db-f345-42b3-a708-dfc2add2d4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
